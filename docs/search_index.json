[["index.html", "A Minimal Book Example Chapter 1 Prerequisites", " A Minimal Book Example Yihui Xie 2021-01-26 Chapter 1 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc's Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. "],["introduction.html", "Chapter 2 Introduction", " Chapter 2 Introduction Hoe commit je? (overbodig) in terminal: git add . git commit -m&quot;plaats hier tekst&quot; git status git branch M Naam geven bestanden: nummer + hoofdstuk + functie 04-Bversie-untar-files Hier hebben we het over het doel van het experiment We hebben de code op sommige plekken een beetje aangepast, zodat in het verslag ook te zien is wat er gebeurd. In dit verslag lopen we langs alle stappen van de Hardcode (hierboven uitgelegd). Per &quot;code chunk&quot; wordt uitgelegd wat de functie/werking/doel is. Differential expression analysis This analysis used the DESeq2 workflow by Love et al., 2014(^ Love, M.I., Huber, W. &amp; Anders, S. Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15, 550 (2014). https://doi.org/10.1186/s13059-014-0550-8) loading libraries and setting root Alle functies zijn opgeslagen in library's deze moeten we dus eerst downloaden en ophalen. uitleggen #find the root file root &lt;- find_root_file(criterion = is_rstudio_project) We leggen voor elk stukje code uit wat er gebeurd en waarom. De code is zo opgedeeld dat elk stukje code uitgelegd kan worden, en gevisualiseerd. kleine aanpassing test "],["the-hardcode-the-beta-version-of-the-dashboard.html", "Chapter 3 The hardcode - the beta version of the dashboard 3.1 inleiding shiny dashboard", " Chapter 3 The hardcode - the beta version of the dashboard In this part we'll explain each part of our version of the dashboard. This chapter contains the following sub-chapters (hier dingen zoeken om het anders weer te geven, ook linkjes maken zodat je meteen naar dit hoofdstuk kan etc etc) Get the first data of the experiment : in this chapter the following things will be discussed and explained... Untar the data. Unzipping of the downloaded data Make data ready for SummarizedExperiment and DESeq2 Genarating a summarized experiment for (CSV) SummarizedExperiment (S) iSEE DESeq2 analysis The visualization of the dataset Heatmap PCA Histogram Vulcan-plot 3.0.1 Get the first data of the experiment With the functions below the data from the selected experiment will be downloaded. The first steps are to collect the data of the experiment and the supplementary files (supp_files from now on). Inside the supp_files are the raw data of the experimnet, a supp_file can be any kind of file. For our project we've focused on csv files only. Before we can download the files we need to make a directory, this is for... . After that we need to make sure R knows what we want to work with. We can do this with PARAMS, you can find them at the top of the Rmarkdown documents. The params we use are geo_dataset(put the number of your experiemnt from NCBI_GEO (LINKJE)), params data1 and data2 will be explained later. When you want to analyze several experiments at the same time (not recommended) R needs to split the experiments, so it won't read the params as 1 experiment. We do this with the first code chunk, in this chunk, folders are also made for the (different) experiments #make a directory #create_dir &lt;- function(path) { # #} #When there are more params the (function) &quot;datasets&quot; will split them datasets &lt;- strsplit(params$geo_dataset, split = &quot; &quot;) %&gt;% unlist #With full_paths each parameter will be full_paths &lt;- file.path(here::here(), datasets) #Make maps for the different experiments inside geo_dataset purrr::walk( full_paths, dir.create) Now R knows with what kind of data we want to work with, we can download the first set of data. We do this with the function “map2” the .x tells what data to look for and .y where to put it. The function getGEO does all the magic to get the data. You might notice at .y we used full_paths, we made this directory in the last code chunk, it gives the location of the folder for each experiment. #download the data data &lt;- map2( .x = datasets, .y = full_paths, getGEO, GSEMatrix = TRUE, filename = NULL ) ## Found 1 file(s) ## GSE150646_series_matrix.txt.gz ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## .default = col_character() ## ) ## ℹ Use `spec()` for the full column specifications. ## File stored at: ## /home/jelmer_oedzes/New-eindverslag/New_new_research_project/GSE150646/GPL18694.soft With the first data, about the experiment, downloaded, it’s time to get the supp_files. We use the same map2 function from before but now with the function “getGEOSuppFiles”. This will get the supp_files from the selected experiment. #Get supp files data_supp &lt;- map2( .x = datasets, .y = full_paths, getGEOSuppFiles, makeDirectory = FALSE, #baseDir = getwd(), fetch_files = TRUE, filter_regex = NULL ) Now we’ve downloaded the experimental data (supp_files), we need to unpack them. Supp_files are often zipped or tarred, our next job is to unzip and or untar these files. First we’ll explain the untarring of files then after that the unzipping of the data. 3.0.2 Untar the data. To untar the data we first need to tell R where to find the tarred files. We do this with the first line of code, this contains the location of the files. We only select the tarred files with the pattern function. We tell the map function with .x where to look for the tarred data and with .f to untar these files. The last thing we tell map to do is making a new folder. We do this with exdir, this is needed because in a tarred file there are several smaller files, they need a place to go. Because the location is now different, we made an unzip function inside the untar code chunk. #To untar more files (from different geo_datasets doesn&#39;t work yet) files_tar &lt;- list.files(path = here::here(datasets), full.names = TRUE, pattern = &quot;.tar&quot;) untarr &lt;- map( .x = files_tar, .f = untar, exdir = file.path(root, params$geo_dataset , &quot;untarred&quot;) ) ## Untarred files will be unzipped ##voor nu gebruiken &quot;Probleem&quot; normaal gebruiken &gt; datasets (zonder &quot;&quot;) (weet niet meer waarom dit er staat en of het is opgelost) list_for_unzipping &lt;- list.files(file.path(root, datasets, &quot;untarred&quot;), full.names = TRUE) lapply(list_for_unzipping, gunzip) ## list() 3.0.2.1 Unzipping of the downloaded data We start the same way as “untar the data”, we tell R where to find the zipped files and select them with the pattern “.gz”. The new map function will then unzip the files with function GEOquery::gunzip files_zip &lt;- list.files(path = here::here(datasets), full.names = TRUE, pattern = &quot;.gz&quot;) unzipp &lt;- map( .x = files_zip, .f = GEOquery::gunzip ) In these first few steps we have: Downloaded supp_files and data about the experiment and unpacked these files. The next steps will be making sure the data is ready for data-analysis. 3.0.3 Make data ready for SummarizedExperiment and DESeq2 3.0.3.1 Genarating a summarized experiment for (CSV) The first steps in making a summarized experiment are getting the phenodata and metadata. Before we do that we first check if we still have the correct data selected. The glimpse(datasets) should give the same output as your selected experiment (params geo_dataset) in this case that is GSE150646. After this quick check we want to know how to get to our data and make this easier. We see that that the data is saved in a folder inside a folder. To get to the data we need to do the same function twice, that’s why we called the first one 'pre'. Now we can easily ge our data with gse_csv. #We look into the datasets to check if we have selected the experiments we want to work with. glimpse(datasets) ## chr &quot;GSE150646&quot; glimpse(data) ## List of 1 ## $ :List of 1 ## ..$ GSE150646_series_matrix.txt.gz:Formal class &#39;ExpressionSet&#39; [package &quot;Biobase&quot;] with 7 slots #To get to the data we need to do the same function twice, thats why we called the first one &#39;pre&#39; pre_gse_csv &lt;- data[[1]] gse_csv &lt;- pre_gse_csv[[1]] glimpse(gse_csv) ## Formal class &#39;ExpressionSet&#39; [package &quot;Biobase&quot;] with 7 slots ## ..@ experimentData :Formal class &#39;MIAME&#39; [package &quot;Biobase&quot;] with 13 slots ## ..@ assayData :&lt;environment: 0x55ac81f4bc98&gt; ## ..@ phenoData :Formal class &#39;AnnotatedDataFrame&#39; [package &quot;Biobase&quot;] with 4 slots ## ..@ featureData :Formal class &#39;AnnotatedDataFrame&#39; [package &quot;Biobase&quot;] with 4 slots ## ..@ annotation : chr &quot;GPL18694&quot; ## ..@ protocolData :Formal class &#39;AnnotatedDataFrame&#39; [package &quot;Biobase&quot;] with 4 slots ## ..@ .__classVersion__:Formal class &#39;Versions&#39; [package &quot;Biobase&quot;] with 1 slot Now we know that we’ve the correct data and can easily access them we’ll make the phenodata and metadata. We only need 2 functions to do this, pData and experimentData. #obtaining phenotypic data. contains all the info regarding each sample. #werkt niet phenodata_csv &lt;- pData(gse_csv) %&gt;% as_tibble class(phenodata_csv) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; #metadata maken en controleren of dit klopt metadata_csv &lt;- experimentData(gse_csv) #class(metadata_csv) Now we need to “clean up” the phenodata a little bit before we can continue making a summarizedExperiment. When we look at the phenodata (with head) we see some weird names like “characteristics_ch1.1” and “characteristics_ch1.2”, these are the variables of the experiments. When you read “characteristics_ch1.1” you’ve no clue what the experiment is about, so you can change the name (for example) to gender/dev_stage/genotype etc. You can change the names with the params data1 and data2 at the start of this document. The place of “characteristics_ch1.1” can change from experiment to experiment, we haven’t find a way to automate this yet. #To look at what columm (number) the characteristics are, this can change per research, we haven&#39;t automated this yet. names(phenodata_csv) ## [1] &quot;title&quot; &quot;geo_accession&quot; ## [3] &quot;status&quot; &quot;submission_date&quot; ## [5] &quot;last_update_date&quot; &quot;type&quot; ## [7] &quot;channel_count&quot; &quot;source_name_ch1&quot; ## [9] &quot;organism_ch1&quot; &quot;characteristics_ch1&quot; ## [11] &quot;characteristics_ch1.1&quot; &quot;characteristics_ch1.2&quot; ## [13] &quot;treatment_protocol_ch1&quot; &quot;molecule_ch1&quot; ## [15] &quot;extract_protocol_ch1&quot; &quot;extract_protocol_ch1.1&quot; ## [17] &quot;extract_protocol_ch1.2&quot; &quot;taxid_ch1&quot; ## [19] &quot;data_processing&quot; &quot;data_processing.1&quot; ## [21] &quot;data_processing.2&quot; &quot;data_processing.3&quot; ## [23] &quot;platform_id&quot; &quot;contact_name&quot; ## [25] &quot;contact_email&quot; &quot;contact_department&quot; ## [27] &quot;contact_institute&quot; &quot;contact_address&quot; ## [29] &quot;contact_city&quot; &quot;contact_zip/postal_code&quot; ## [31] &quot;contact_country&quot; &quot;data_row_count&quot; ## [33] &quot;instrument_model&quot; &quot;library_selection&quot; ## [35] &quot;library_source&quot; &quot;library_strategy&quot; ## [37] &quot;relation&quot; &quot;relation.1&quot; ## [39] &quot;supplementary_file_1&quot; &quot;age:ch1&quot; ## [41] &quot;genotype:ch1&quot; &quot;strain:ch1&quot; # Het benoemen van experimentele waarde colnames(phenodata_csv)[11] &lt;- params$data1 colnames(phenodata_csv)[12] &lt;- params$data2 names(phenodata_csv) ## [1] &quot;title&quot; &quot;geo_accession&quot; ## [3] &quot;status&quot; &quot;submission_date&quot; ## [5] &quot;last_update_date&quot; &quot;type&quot; ## [7] &quot;channel_count&quot; &quot;source_name_ch1&quot; ## [9] &quot;organism_ch1&quot; &quot;characteristics_ch1&quot; ## [11] &quot;dev_stage&quot; &quot;genotype&quot; ## [13] &quot;treatment_protocol_ch1&quot; &quot;molecule_ch1&quot; ## [15] &quot;extract_protocol_ch1&quot; &quot;extract_protocol_ch1.1&quot; ## [17] &quot;extract_protocol_ch1.2&quot; &quot;taxid_ch1&quot; ## [19] &quot;data_processing&quot; &quot;data_processing.1&quot; ## [21] &quot;data_processing.2&quot; &quot;data_processing.3&quot; ## [23] &quot;platform_id&quot; &quot;contact_name&quot; ## [25] &quot;contact_email&quot; &quot;contact_department&quot; ## [27] &quot;contact_institute&quot; &quot;contact_address&quot; ## [29] &quot;contact_city&quot; &quot;contact_zip/postal_code&quot; ## [31] &quot;contact_country&quot; &quot;data_row_count&quot; ## [33] &quot;instrument_model&quot; &quot;library_selection&quot; ## [35] &quot;library_source&quot; &quot;library_strategy&quot; ## [37] &quot;relation&quot; &quot;relation.1&quot; ## [39] &quot;supplementary_file_1&quot; &quot;age:ch1&quot; ## [41] &quot;genotype:ch1&quot; &quot;strain:ch1&quot; Further change of the phnodata, needed to make Summarized Experiment. # phenodata_csv &lt;- phenodata_csv[2:41] samplenames_csv&lt;- phenodata_csv[1] 3.0.3.2 Last steps before SummarizedExperiment Now we can load the CSV_file, you’ll see the first few counts inside the file. Check if the data file is a “data.frame. #Load the raw data from the csv data load_csv_data &lt;- list.files(path = here::here(params$geo_dataset), full.names = TRUE, pattern = &quot;.csv&quot;) csv_data &lt;- read.csv(load_csv_data) #the first few counts of the raw data head(csv_data) ## Ensembl_geneID I16R020c01 I16R020c03 I16R020c04 I16R020c05 I16R020c06 ## 1 ENSRNOG00000040300 0 1 0 1 1 ## 2 ENSRNOG00000061316 7 5 1 6 1 ## 3 ENSRNOG00000050129 0 0 1 0 0 ## 4 ENSRNOG00000029897 0 0 0 2 0 ## 5 ENSRNOG00000042852 0 2 0 0 0 ## 6 ENSRNOG00000014303 4001 3825 3810 4494 3934 ## I16R020d01 I16R020d02 I16R020d03 I16R020d04 I16R020d06 I16R043g01 I16R043g04 ## 1 2 0 0 0 2 0 1 ## 2 1 2 1 2 2 10 6 ## 3 0 0 0 0 0 0 0 ## 4 1 1 0 2 1 1 4 ## 5 0 0 0 0 0 0 1 ## 6 4014 4167 4254 4811 4462 4406 4883 ## I16R043g05 I16R043g06 I16R043g07 I16R043h02 I16R043h03 I16R043h05 I16R043h06 ## 1 0 2 1 0 0 2 1 ## 2 2 2 6 3 4 8 7 ## 3 0 0 0 0 0 2 0 ## 4 1 2 4 5 0 5 6 ## 5 0 0 0 0 0 0 1 ## 6 5092 4935 5546 5870 5646 5316 4742 ## I16R043h07 ## 1 0 ## 2 2 ## 3 0 ## 4 4 ## 5 0 ## 6 5534 #Check if the csv_data is a data.frame class(csv_data) ## [1] &quot;data.frame&quot; In raw_counts_csv_data we load in the raw counts of the csv file, minus the first column because these are names of the samples. Also note that it can be more or less columns in different documents. In the next step we change the name of the columns to make them more understandable. The last step is to change the data.frame into a data.matrix for SummarizedExperiment. ## In het volgende stukje willen we dat de namen goed komen te staan, je ziet eerst dat het rommelig is en daarna hebben ze GSM nummers #Laat alleen de raw counts over raw_counts_csv_data &lt;- csv_data[2:21] #head(raw_counts_csv_data) ##make rowdata_csv rowdata_csv_data &lt;- raw_counts_csv_data$`Gene symbol` #Kan ik de raw_counts_csv_data gebruiken om colnames te maken test colnames(raw_counts_csv_data) &lt;-samplenames_csv[[1]] head(raw_counts_csv_data) ## GSM4555720 GSM4555721 GSM4555722 GSM4555723 GSM4555724 GSM4555725 GSM4555726 ## 1 0 1 0 1 1 2 0 ## 2 7 5 1 6 1 1 2 ## 3 0 0 1 0 0 0 0 ## 4 0 0 0 2 0 1 1 ## 5 0 2 0 0 0 0 0 ## 6 4001 3825 3810 4494 3934 4014 4167 ## GSM4555727 GSM4555728 GSM4555729 GSM4555730 GSM4555731 GSM4555732 GSM4555733 ## 1 0 0 2 0 1 0 2 ## 2 1 2 2 10 6 2 2 ## 3 0 0 0 0 0 0 0 ## 4 0 2 1 1 4 1 2 ## 5 0 0 0 0 1 0 0 ## 6 4254 4811 4462 4406 4883 5092 4935 ## GSM4555734 GSM4555735 GSM4555736 GSM4555737 GSM4555738 GSM4555739 ## 1 1 0 0 2 1 0 ## 2 6 3 4 8 7 2 ## 3 0 0 0 2 0 0 ## 4 4 5 0 5 6 4 ## 5 0 0 0 0 1 0 ## 6 5546 5870 5646 5316 4742 5534 #maak er een matrix van, weet niet waarom raw_counts_csv_data_matrix &lt;- data.matrix(raw_counts_csv_data) rownames(raw_counts_csv_data_matrix) &lt;- rowdata_csv_data #head(raw_counts_csv_data_matrix) 3.1 inleiding shiny dashboard 3.1.0.1 Deseq2 function 3.1.1 Make DESeq2 tab This page is quite simple, we make a box where the data will be rendered. With an actionbutton the user will be able to activate the &quot;deseq2_function&quot; "]]
